{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0e64d9-a035-4f31-a945-eed39195dc19",
   "metadata": {},
   "source": [
    "# From Scratch MNIST Classification Using an Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0fcd16-2c0d-4498-828c-e4b84cdb23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c55fcb0-0e70-4787-ae1a-2a52f28141c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8dccf2c-5cd8-42ca-a0f1-72310a8cd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(-1, 784).astype('float32') / 255.0\n",
    "test_images = test_images.reshape(-1, 784).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58204ca9-8422-4cae-a90a-bea0ce55048c",
   "metadata": {},
   "source": [
    "### Explanation: Loading and Preprocessing MNIST Data\n",
    "\n",
    "**Reshape the Data:**\n",
    "   - **`reshape(-1, 784)`**:\n",
    "     - Reshapes each image from 28x28 to a flat 784-dimensional vector (`28 * 28 = 784`).\n",
    "     - `-1` lets NumPy infer the correct number of samples from the dataset.\n",
    "   - **`.astype('float32')`**:\n",
    "     - Converts the pixel values to 32-bit floating-point numbers for better numerical precision during training.\n",
    "   - **`/ 255.0`**:\n",
    "     - Normalizes the pixel values to the range `[0, 1]` by dividing by the maximum pixel intensity (255).\n",
    "     - Normalization helps the neural network converge faster during training by ensuring consistent data scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12b0f27-2f66-4b0c-8a3c-f4cc2c9506d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d5dc22-c5e9-443f-b97c-c9f294f31875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "train_labels_one_hot = np.eye(10)[train_labels]\n",
    "test_labels_one_hot = np.eye(10)[test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80367b2f-fe79-4446-a2ce-198f3a5cbd17",
   "metadata": {},
   "source": [
    "### Explanation: One-Hot Encoding Labels\n",
    "\n",
    "1. **What Is One-Hot Encoding?**\n",
    "   - One-hot encoding transforms categorical labels into binary vectors.\n",
    "   - Example: The digit `3` becomes `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`.\n",
    "\n",
    "2. **How It Works:**\n",
    "   - `np.eye(10)` creates a 10x10 identity matrix:\n",
    "     ```\n",
    "     [[1, 0, 0, ..., 0],\n",
    "      [0, 1, 0, ..., 0],\n",
    "      [0, 0, 1, ..., 0],\n",
    "      ...]\n",
    "     ```\n",
    "   - Indexing `np.eye(10)[train_labels]` selects the corresponding row from the identity matrix based on the label's value.\n",
    "\n",
    "3. **Why Use It?**\n",
    "   - One-hot encoding is essential for multi-class classification.\n",
    "   - It allows the neural network's output to be compared directly with the one-hot labels when calculating loss using categorical cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91eb0eb5-91ac-435e-90c4-fd140b02e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_images, train_labels_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1d7600-406c-4cf7-a3d0-f3fcc5e11592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters with He initialization\n",
    "def initialize_parameters():\n",
    "    parameters = {\n",
    "        'W1': np.random.randn(256, 784) * np.sqrt(2. / 784),\n",
    "        'b1': np.zeros((256, 1)),\n",
    "        'W2': np.random.randn(128, 256) * np.sqrt(2. / 256),\n",
    "        'b2': np.zeros((128, 1)),\n",
    "        'W3': np.random.randn(10, 128) * np.sqrt(2. / 128),\n",
    "        'b3': np.zeros((10, 1))\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790179a0-b95b-435d-ba19-36facc4c9cad",
   "metadata": {},
   "source": [
    "### Explanation: Initializing Parameters with He Initialization\n",
    "\n",
    "The function `initialize_parameters()` initializes weights and biases for a 3-layer neural network using **He initialization**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why He Initialization?**\n",
    "- He initialization sets the weights using a scaled normal distribution.\n",
    "- It helps avoid vanishing/exploding gradients, ensuring stable training.\n",
    "- Formula:  \n",
    "  $\n",
    "  W = \\text{np.random.randn}(n_{\\text{out}}, n_{\\text{in}}) \\times \\sqrt{\\frac{2}{n_{\\text{in}}}}\n",
    "  $\n",
    "  Where:\n",
    "  - $(n_{\\text{in}})$: Number of input units from the previous layer.\n",
    "  - $(n_{\\text{out}})$: Number of output units in the current layer.\n",
    "\n",
    "---\n",
    "\n",
    "1. **Layer 1 (Input to First Hidden Layer):**\n",
    "   - `W1`: Weight matrix of shape **(256, 784)**.\n",
    "   - `b1`: Bias vector of shape **(256, 1)** initialized to zeros.\n",
    "\n",
    "2. **Layer 2 (Hidden Layer to Second Hidden Layer):**\n",
    "   - `W2`: Weight matrix of shape **(128, 256)**.\n",
    "   - `b2`: Bias vector of shape **(128, 1)** initialized to zeros.\n",
    "\n",
    "3. **Layer 3 (Second Hidden Layer to Output Layer):**\n",
    "   - `W3`: Weight matrix of shape **(10, 128)**.\n",
    "   - `b3`: Bias vector of shape **(10, 1)** initialized to zeros.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Zero Bias Initialization?**\n",
    "- Bias terms are initialized to zero because they donâ€™t depend on input variance and are learned during training.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why This Matters?**\n",
    "- Proper initialization ensures:\n",
    "  - Faster convergence.\n",
    "  - Reduced risk of getting stuck in poor local minima.\n",
    "  - Stable gradients during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b95225b6-4c10-4ab5-8d1c-a14eabe3ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    return Z > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f281aaa-3b69-4c2d-9008-0247d45ad6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_propagation(X, parameters):\n",
    "    Z1 = np.dot(parameters['W1'], X.T) + parameters['b1']\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(parameters['W2'], A1) + parameters['b2']\n",
    "    A2 = relu(Z2)\n",
    "    Z3 = np.dot(parameters['W3'], A2) + parameters['b3']\n",
    "    A3 = softmax(Z3)\n",
    "    cache = (Z1, A1, Z2, A2, Z3, A3)\n",
    "    return A3, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2309ca-ab08-4523-9525-455353fa637e",
   "metadata": {},
   "source": [
    "### Explanation: Forward Propagation\n",
    "\n",
    "The function `forward_propagation(X, parameters)` performs forward propagation through a 3-layer neural network. It computes the network's predictions by passing the input through the layers sequentially.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step-by-Step Breakdown:**\n",
    "\n",
    "#### 1. **Layer 1 (Input to First Hidden Layer):**\n",
    "```python\n",
    "Z1 = np.dot(parameters['W1'], X.T) + parameters['b1']\n",
    "A1 = relu(Z1)\n",
    "```\n",
    "- **Z1:**  \n",
    "  - Linear transformation:  \n",
    "    $\n",
    "    Z_1 = W_1 \\cdot X^T + b_1\n",
    "    $\n",
    "  - Shape: **(256, Number of Samples)**\n",
    "\n",
    "- **A1:**  \n",
    "  - Activation using **ReLU**:  \n",
    "    $\n",
    "    A_1 = \\text{ReLU}(Z_1) = \\max(0, Z_1)\n",
    "    $\n",
    "  - This introduces non-linearity to the model.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Layer 2 (Hidden Layer to Next Hidden Layer):**\n",
    "```python\n",
    "Z2 = np.dot(parameters['W2'], A1) + parameters['b2']\n",
    "A2 = relu(Z2)\n",
    "```\n",
    "- **Z2:**  \n",
    "  - Linear transformation:  \n",
    "    $\n",
    "    Z_2 = W_2 \\cdot A_1 + b_2\n",
    "    $\n",
    "  - Shape: **(128, Number of Samples)**\n",
    "\n",
    "- **A2:**  \n",
    "  - Activation using **ReLU**:  \n",
    "    $\n",
    "    A_2 = \\text{ReLU}(Z_2)\n",
    "    $\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Layer 3 (Second Hidden Layer to Output Layer):**\n",
    "```python\n",
    "Z3 = np.dot(parameters['W3'], A2) + parameters['b3']\n",
    "A3 = softmax(Z3)\n",
    "```\n",
    "- **Z3:**  \n",
    "  - Linear transformation:  \n",
    "    $\n",
    "    Z_3 = W_3 \\cdot A_2 + b_3\n",
    "    $\n",
    "  - Shape: **(10, Number of Samples)**\n",
    "\n",
    "- **A3:**  \n",
    "  - Activation using **Softmax**:  \n",
    "    $\n",
    "    A_3 = \\text{Softmax}(Z_3) = \\frac{e^{Z_3}}{\\sum e^{Z_3}}\n",
    "    $\n",
    "  - This outputs probabilities for each of the 10 possible classes (digits 0-9).\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Save to Cache?**\n",
    "```python\n",
    "cache = (Z1, A1, Z2, A2, Z3, A3)\n",
    "```\n",
    "- **Why Cache?**\n",
    "  - Caching intermediate results (`Z1`, `A1`, `Z2`, `A2`, `Z3`, `A3`) simplifies the backward pass during backpropagation.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Is Returned?**\n",
    "```python\n",
    "return A3, cache\n",
    "```\n",
    "- **A3:** The networkâ€™s predictions (output probabilities).\n",
    "- **cache:** Cached results needed for backpropagation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary:**\n",
    "- Forward propagation computes activations and outputs layer by layer.\n",
    "- It combines linear transformations (`Z`) and activations (`A`).\n",
    "- It returns the predictions and intermediate results for learning through backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afeb7632-5f41-49c7-b13f-4be2d212fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "def back_propagation(X, Y, parameters, cache):\n",
    "    m = X.shape[0]\n",
    "    Z1, A1, Z2, A2, Z3, A3 = cache\n",
    "\n",
    "    dZ3 = A3\n",
    "    dZ3[Y.argmax(axis=1), np.arange(m)] -= 1\n",
    "    dW3 = np.dot(dZ3, A2.T) / m\n",
    "    db3 = np.sum(dZ3, axis=1, keepdims=True) / m\n",
    "\n",
    "    dA2 = np.dot(parameters['W3'].T, dZ3)\n",
    "    dZ2 = dA2 * relu_derivative(Z2)\n",
    "    dW2 = np.dot(dZ2, A1.T) / m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "\n",
    "    dA1 = np.dot(parameters['W2'].T, dZ2)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = np.dot(dZ1, X) / m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "\n",
    "    grads = {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2, 'dW3': dW3, 'db3': db3}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f775407f-0b06-4049-b7a4-401f9838011f",
   "metadata": {},
   "source": [
    "### Explanation: Backward Propagation\n",
    "\n",
    "The function `back_propagation(X, Y, parameters, cache)` computes the gradients of the cost function with respect to the network parameters using the **chain rule**. These gradients are used to update the weights and biases during training.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step-by-Step Breakdown:**\n",
    "\n",
    "#### 1. **Extract Cached Values:**\n",
    "```python\n",
    "m = X.shape[0]\n",
    "Z1, A1, Z2, A2, Z3, A3 = cache\n",
    "```\n",
    "- `m`: Number of training samples.\n",
    "- The cached values from the forward pass are unpacked to avoid recomputation.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Output Layer Gradients:**\n",
    "```python\n",
    "dZ3 = A3\n",
    "dZ3[Y.argmax(axis=1), np.arange(m)] -= 1\n",
    "dW3 = np.dot(dZ3, A2.T) / m\n",
    "db3 = np.sum(dZ3, axis=1, keepdims=True) / m\n",
    "```\n",
    "- **dZ3:** Error at the output layer:  \n",
    "  $\n",
    "  dZ_3 = A_3 - Y\n",
    "  $\n",
    "  This adjusts the predicted probabilities `A3` by subtracting the true labels `Y` using one-hot encoding.\n",
    "\n",
    "- **dW3:** Gradient of the loss with respect to `W3`:  \n",
    "  $\n",
    "  dW_3 = \\frac{1}{m} dZ_3 \\cdot A_2^T\n",
    "  $\n",
    "\n",
    "- **db3:** Gradient of the loss with respect to `b3`:  \n",
    "  $\n",
    "  db_3 = \\frac{1}{m} \\sum dZ_3\n",
    "  $\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Second Hidden Layer Gradients:**\n",
    "```python\n",
    "dA2 = np.dot(parameters['W3'].T, dZ3)\n",
    "dZ2 = dA2 * relu_derivative(Z2)\n",
    "dW2 = np.dot(dZ2, A1.T) / m\n",
    "db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "```\n",
    "- **dA2:** Propagated error from the next layer:  \n",
    "  $\n",
    "  dA_2 = W_3^T \\cdot dZ_3\n",
    "  $\n",
    "\n",
    "- **dZ2:** Applying ReLU derivative:  \n",
    "  $\n",
    "  dZ_2 = dA_2 \\odot \\text{ReLU}'(Z_2)\n",
    "  $\n",
    "\n",
    "- **dW2 and db2:** Weight and bias gradients for layer 2.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **First Hidden Layer Gradients:**\n",
    "```python\n",
    "dA1 = np.dot(parameters['W2'].T, dZ2)\n",
    "dZ1 = dA1 * relu_derivative(Z1)\n",
    "dW1 = np.dot(dZ1, X) / m\n",
    "db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "```\n",
    "- **dA1:** Propagated error from the previous layer:  \n",
    "  $\n",
    "  dA_1 = W_2^T \\cdot dZ_2\n",
    "  $\n",
    "\n",
    "- **dZ1:** Applying ReLU derivative:  \n",
    "  \\[\n",
    "  dZ_1 = dA_1 \\odot \\text{ReLU}'(Z_1)\n",
    "  \\]\n",
    "\n",
    "- **dW1 and db1:** Weight and bias gradients for layer 1.\n",
    "\n",
    "---\n",
    "\n",
    "### **Collect Gradients:**\n",
    "```python\n",
    "grads = {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2, 'dW3': dW3, 'db3': db3}\n",
    "```\n",
    "- The computed gradients are stored in a dictionary `grads`.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Is Returned?**\n",
    "```python\n",
    "return grads\n",
    "```\n",
    "- **Returns:** A dictionary containing all the computed gradients for use in parameter updates.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why This Matters:**\n",
    "- Backpropagation efficiently computes the gradients using the **chain rule**.\n",
    "- These gradients enable the network to learn by adjusting its weights and biases through **gradient descent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8449f5ac-8d54-40b2-b37c-e5a14443c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradient descent\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    for key in parameters.keys():\n",
    "        parameters[key] -= learning_rate * grads['d' + key]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e482c-d546-4ed8-9df0-274145a243d3",
   "metadata": {},
   "source": [
    "### Explanation: Update Parameters with Gradient Descent\n",
    "\n",
    "The function `update_parameters(parameters, grads, learning_rate)` adjusts the neural network's weights and biases using the computed gradients from backpropagation. This process follows the **gradient descent algorithm**.\n",
    "\n",
    "---\n",
    "\n",
    "### **How It Works:**\n",
    "\n",
    "1. **Loop Through Each Parameter:**\n",
    "   ```python\n",
    "   for key in parameters.keys():\n",
    "       parameters[key] -= learning_rate * grads['d' + key]\n",
    "   ```\n",
    "   - The function iterates through all the keys in the `parameters` dictionary, which contains:\n",
    "     - `W1`, `b1` â†’ First layer weights and biases.\n",
    "     - `W2`, `b2` â†’ Second layer weights and biases.\n",
    "     - `W3`, `b3` â†’ Third layer weights and biases.\n",
    "\n",
    "2. **Gradient Descent Update Rule:**\n",
    "   - For each parameter $( \\theta )$, the update rule is:\n",
    "     $\n",
    "     \\theta = \\theta - \\alpha \\cdot \\frac{\\partial J}{\\partial \\theta}\n",
    "     $\n",
    "   - Where:\n",
    "     - $( \\theta )$: Current parameter (weights or biases).\n",
    "     - $( \\alpha )$: Learning rate (step size).\n",
    "     - $( \\frac{\\partial J}{\\partial \\theta} )$: Gradient of the parameter from backpropagation.\n",
    "\n",
    "3. **Specific Updates:**\n",
    "   - **Weights Update:**\n",
    "     ```python\n",
    "     parameters['W1'] -= learning_rate * grads['dW1']\n",
    "     parameters['W2'] -= learning_rate * grads['dW2']\n",
    "     parameters['W3'] -= learning_rate * grads['dW3']\n",
    "     ```\n",
    "   - **Biases Update:**\n",
    "     ```python\n",
    "     parameters['b1'] -= learning_rate * grads['db1']\n",
    "     parameters['b2'] -= learning_rate * grads['db2']\n",
    "     parameters['b3'] -= learning_rate * grads['db3']\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why This Matters:**\n",
    "- The weights and biases are updated using their corresponding gradients, moving the parameters **opposite** to the gradient direction (minimizing the cost).\n",
    "- This process gradually reduces the loss and improves the model's performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Return Statement:**\n",
    "```python\n",
    "return parameters\n",
    "```\n",
    "- The function returns the updated parameters, which are used in the next training iteration.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Itâ€™s Important:**\n",
    "- **Learning Rate Tuning:** A properly chosen learning rate ensures efficient training:\n",
    "  - **Too Small:** Slow convergence.\n",
    "  - **Too Large:** Risk of overshooting the minimum.\n",
    "- **Efficient Updates:** This function keeps the update process clean and scalable for larger models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f09a7a-0fe8-42d7-9c4a-4be9be5e2a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function\n",
    "def predict(X, parameters):\n",
    "    Y_hat, _ = forward_propagation(X, parameters)\n",
    "    return np.argmax(Y_hat, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ab56d-8c04-4da6-965e-45b1999a9c78",
   "metadata": {},
   "source": [
    "### Explanation: Predict Function\n",
    "\n",
    "The function `predict(X, parameters)` makes predictions using the trained neural network by performing **forward propagation**.\n",
    "\n",
    "---\n",
    "\n",
    "### **How It Works:**\n",
    "\n",
    "1. **Forward Propagation:**\n",
    "   ```python\n",
    "   Y_hat, _ = forward_propagation(X, parameters)\n",
    "   ```\n",
    "   - The input `X` is passed through the network using the `forward_propagation()` function.\n",
    "   - `Y_hat` contains the predicted probabilities for each class (digits 0-9).\n",
    "   - The cache (`_`) is not used here since backpropagation is not needed during inference.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Select the Most Likely Class:**\n",
    "   ```python\n",
    "   return np.argmax(Y_hat, axis=0)\n",
    "   ```\n",
    "   - `np.argmax(Y_hat, axis=0)` selects the index of the maximum value along each column (sample).\n",
    "   - Since `Y_hat` contains probabilities, the class with the highest probability is the predicted digit.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example:**\n",
    "Suppose `Y_hat` looks like this for a sample:\n",
    "```python\n",
    "Y_hat = [[0.1, 0.05], \n",
    "         [0.2, 0.1], \n",
    "         [0.7, 0.85]]\n",
    "```\n",
    "- `np.argmax(Y_hat, axis=0)` returns:\n",
    "  ```\n",
    "  [2, 2]\n",
    "  ```\n",
    "  Meaning the model predicts class `2` for both samples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why This Matters:**\n",
    "- This function is essential for:\n",
    "  - **Model Evaluation:** Calculating accuracy by comparing predicted labels with actual labels.\n",
    "  - **Model Inference:** Making predictions on new data after training.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "- Performs a forward pass through the network.\n",
    "- Returns the predicted class labels for each input sample.\n",
    "- Used during both validation and testing stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125d5ddf-41fc-403b-9372-8017e03644ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def model(X_train, Y_train, X_val, Y_val, learning_rate=0.001, epochs=10, batch_size=64):\n",
    "    parameters = initialize_parameters()\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            Y_batch = Y_train[i:i+batch_size]\n",
    "            Y_hat, cache = forward_propagation(X_batch, parameters)\n",
    "            loss = -np.mean(np.sum(Y_batch * np.log(Y_hat.T + 1e-8), axis=1))\n",
    "            grads = back_propagation(X_batch, Y_batch, parameters, cache)\n",
    "            parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        Y_train_pred = predict(X_train, parameters)\n",
    "        Y_val_pred = predict(X_val, parameters)\n",
    "\n",
    "        train_accuracy = np.mean(Y_train_pred == np.argmax(Y_train, axis=1))\n",
    "        val_accuracy = np.mean(Y_val_pred == np.argmax(Y_val, axis=1))\n",
    "        val_loss = -np.mean(np.sum(Y_val * np.log(forward_propagation(X_val, parameters)[0].T + 1e-8), axis=1))\n",
    "\n",
    "        train_losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs} - accuracy: {train_accuracy:.4f} - loss: {loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f}')\n",
    "\n",
    "    return parameters, train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c135d06-2e11-4d25-b367-defdaaec15ac",
   "metadata": {},
   "source": [
    "### Explanation: Training the Model\n",
    "\n",
    "The function `model()` trains the neural network using **mini-batch gradient descent** and evaluates its performance after each epoch.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Inputs:**\n",
    "- `X_train`, `Y_train`: Training data and labels.\n",
    "- `X_val`, `Y_val`: Validation data and labels.\n",
    "- `learning_rate`: Controls how much to adjust parameters during updates.\n",
    "- `epochs`: Number of passes through the entire training set.\n",
    "- `batch_size`: Number of samples used in each training step.\n",
    "\n",
    "---\n",
    "\n",
    "### **Training Process Breakdown:**\n",
    "\n",
    "1. **Initialize Parameters:**\n",
    "   ```python\n",
    "   parameters = initialize_parameters()\n",
    "   ```\n",
    "   - Weights and biases are initialized using **He Initialization**.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Tracking Metrics:**\n",
    "   ```python\n",
    "   train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n",
    "   ```\n",
    "   - These lists store training and validation metrics.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Training Loop:**\n",
    "   ```python\n",
    "   for epoch in range(epochs):\n",
    "   ```\n",
    "   - Outer loop runs for each epoch.\n",
    "\n",
    "4. **Mini-Batch Training:**\n",
    "   ```python\n",
    "   for i in range(0, X_train.shape[0], batch_size):\n",
    "       X_batch = X_train[i:i+batch_size]\n",
    "       Y_batch = Y_train[i:i+batch_size]\n",
    "   ```\n",
    "   - The dataset is divided into batches for more stable gradient descent updates.\n",
    "\n",
    "---\n",
    "\n",
    "5. **Forward Propagation:**\n",
    "   ```python\n",
    "   Y_hat, cache = forward_propagation(X_batch, parameters)\n",
    "   ```\n",
    "   - Pass the batch through the network to get predictions `Y_hat` and store intermediate values in `cache`.\n",
    "\n",
    "---\n",
    "\n",
    "6. **Loss Calculation:**\n",
    "   ```python\n",
    "   loss = -np.mean(np.sum(Y_batch * np.log(Y_hat.T + 1e-8), axis=1))\n",
    "   ```\n",
    "   - Use **categorical cross-entropy loss**:  \n",
    "     $\n",
    "     L = - \\frac{1}{m} \\sum Y \\cdot \\log(\\hat{Y} + \\epsilon)\n",
    "     $\n",
    "   - `1e-8` prevents division by zero.\n",
    "\n",
    "---\n",
    "\n",
    "7. **Backward Propagation and Parameter Update:**\n",
    "   ```python\n",
    "   grads = back_propagation(X_batch, Y_batch, parameters, cache)\n",
    "   parameters = update_parameters(parameters, grads, learning_rate)\n",
    "   ```\n",
    "   - Calculate gradients using **backpropagation**.\n",
    "   - Update parameters using **gradient descent**.\n",
    "\n",
    "---\n",
    "\n",
    "8. **Evaluation:**\n",
    "   ```python\n",
    "   Y_train_pred = predict(X_train, parameters)\n",
    "   Y_val_pred = predict(X_val, parameters)\n",
    "   train_accuracy = np.mean(Y_train_pred == np.argmax(Y_train, axis=1))\n",
    "   val_accuracy = np.mean(Y_val_pred == np.argmax(Y_val, axis=1))\n",
    "   ```\n",
    "   - Evaluate the model on both training and validation sets.\n",
    "   - Calculate accuracy by comparing predicted labels with actual labels.\n",
    "\n",
    "---\n",
    "\n",
    "9. **Validation Loss:**\n",
    "   ```python\n",
    "   val_loss = -np.mean(np.sum(Y_val * np.log(forward_propagation(X_val, parameters)[0].T + 1e-8), axis=1))\n",
    "   ```\n",
    "   - Calculate the validation loss using the same categorical cross-entropy formula.\n",
    "\n",
    "---\n",
    "\n",
    "10. **Store Metrics:**\n",
    "   ```python\n",
    "   train_losses.append(loss)\n",
    "   val_losses.append(val_loss)\n",
    "   train_accuracies.append(train_accuracy)\n",
    "   val_accuracies.append(val_accuracy)\n",
    "   ```\n",
    "   - Append the computed metrics to the corresponding lists.\n",
    "\n",
    "---\n",
    "\n",
    "11. **Epoch Summary:**\n",
    "   ```python\n",
    "   print(f'Epoch {epoch+1}/{epochs} - accuracy: {train_accuracy:.4f} - loss: {loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f}')\n",
    "   ```\n",
    "   - Print the progress of each epoch for monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "### **Return Values:**\n",
    "```python\n",
    "return parameters, train_losses, val_losses, train_accuracies, val_accuracies\n",
    "```\n",
    "- **parameters:** Final trained weights and biases.\n",
    "- **train_losses, val_losses:** Loss history for visualization.\n",
    "- **train_accuracies, val_accuracies:** Accuracy history for evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why It Matters:**\n",
    "- **Batch Processing:** Helps stabilize gradient updates and reduce memory usage.\n",
    "- **Metric Tracking:** Allows monitoring of model performance over time.\n",
    "- **Evaluation:** Provides insight into whether the model is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af448bc-cccc-450b-a1a8-7f03fc07973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - accuracy: 0.9115 - loss: 0.3333 - val_accuracy: 0.9050 - val_loss: 0.3378\n",
      "Epoch 2/20 - accuracy: 0.9305 - loss: 0.2513 - val_accuracy: 0.9239 - val_loss: 0.2703\n",
      "Epoch 3/20 - accuracy: 0.9420 - loss: 0.1991 - val_accuracy: 0.9327 - val_loss: 0.2334\n",
      "Epoch 4/20 - accuracy: 0.9497 - loss: 0.1593 - val_accuracy: 0.9404 - val_loss: 0.2080\n",
      "Epoch 5/20 - accuracy: 0.9554 - loss: 0.1298 - val_accuracy: 0.9467 - val_loss: 0.1887\n",
      "Epoch 6/20 - accuracy: 0.9601 - loss: 0.1085 - val_accuracy: 0.9511 - val_loss: 0.1736\n",
      "Epoch 7/20 - accuracy: 0.9642 - loss: 0.0925 - val_accuracy: 0.9539 - val_loss: 0.1615\n",
      "Epoch 8/20 - accuracy: 0.9675 - loss: 0.0813 - val_accuracy: 0.9567 - val_loss: 0.1515\n",
      "Epoch 9/20 - accuracy: 0.9704 - loss: 0.0720 - val_accuracy: 0.9589 - val_loss: 0.1432\n",
      "Epoch 10/20 - accuracy: 0.9726 - loss: 0.0638 - val_accuracy: 0.9613 - val_loss: 0.1363\n",
      "Epoch 11/20 - accuracy: 0.9752 - loss: 0.0562 - val_accuracy: 0.9624 - val_loss: 0.1303\n",
      "Epoch 12/20 - accuracy: 0.9774 - loss: 0.0506 - val_accuracy: 0.9637 - val_loss: 0.1251\n",
      "Epoch 13/20 - accuracy: 0.9792 - loss: 0.0455 - val_accuracy: 0.9647 - val_loss: 0.1206\n",
      "Epoch 14/20 - accuracy: 0.9807 - loss: 0.0417 - val_accuracy: 0.9663 - val_loss: 0.1167\n",
      "Epoch 15/20 - accuracy: 0.9820 - loss: 0.0385 - val_accuracy: 0.9672 - val_loss: 0.1133\n",
      "Epoch 16/20 - accuracy: 0.9834 - loss: 0.0348 - val_accuracy: 0.9679 - val_loss: 0.1104\n",
      "Epoch 17/20 - accuracy: 0.9847 - loss: 0.0319 - val_accuracy: 0.9683 - val_loss: 0.1078\n",
      "Epoch 18/20 - accuracy: 0.9855 - loss: 0.0298 - val_accuracy: 0.9694 - val_loss: 0.1055\n",
      "Epoch 19/20 - accuracy: 0.9864 - loss: 0.0275 - val_accuracy: 0.9702 - val_loss: 0.1035\n",
      "Epoch 20/20 - accuracy: 0.9875 - loss: 0.0254 - val_accuracy: 0.9703 - val_loss: 0.1016\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "parameters, train_losses, val_losses, train_accuracies, val_accuracies = model(X_train,\n",
    "                                                                               Y_train,\n",
    "                                                                               X_val,\n",
    "                                                                               Y_val,\n",
    "                                                                              learning_rate=0.01,\n",
    "                                                                              epochs=20,\n",
    "                                                                              batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e4906-a932-46cb-bf78-e376ccf0691d",
   "metadata": {},
   "source": [
    "### Explanation: Training the Model with Specific Hyperparameters\n",
    "\n",
    "### **What Happens Here?**\n",
    "\n",
    "#### **1. Data Provided:**\n",
    "- **`X_train`, `Y_train`**: Training data and labels.\n",
    "- **`X_val`, `Y_val`**: Validation data and labels.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Training Hyperparameters:**\n",
    "1. **`learning_rate=0.01`**:\n",
    "   - Controls the step size during gradient descent updates.\n",
    "   - A higher learning rate speeds up training but risks overshooting the minimum.\n",
    "   \n",
    "2. **`epochs=20`**:\n",
    "   - The model will iterate over the entire training set 20 times.\n",
    "\n",
    "3. **`batch_size=32`**:\n",
    "   - The model processes 32 samples at a time before updating the parameters.\n",
    "   - This stabilizes training and reduces memory usage.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. What Is Returned:**\n",
    "- **`parameters`**: The trained model's weights and biases.\n",
    "- **`train_losses`**: Training loss history over epochs.\n",
    "- **`val_losses`**: Validation loss history over epochs.\n",
    "- **`train_accuracies`**: Training accuracy history.\n",
    "- **`val_accuracies`**: Validation accuracy history.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why These Settings Matter:**\n",
    "1. **Learning Rate**: `0.01` is a moderate value that balances speed and stability.\n",
    "2. **Epochs**: 20 is a reasonable choice for testing the model's performance.\n",
    "3. **Batch Size**: 32 is commonly used because it balances speed and memory efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Itâ€™s Important:**\n",
    "- These parameters directly affect the model's convergence, performance, and generalization.\n",
    "- Monitoring loss and accuracy helps in diagnosing issues like **overfitting** or **underfitting**. Let me know if you need a more detailed explanation on any specific part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c30a6187-4938-4597-b651-ad1dcd756d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9717\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "Y_test_pred = predict(test_images, parameters)\n",
    "test_accuracy = np.mean(Y_test_pred == test_labels)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cdbb79-0760-4388-8b2a-98458a0faee9",
   "metadata": {},
   "source": [
    "### Explanation: Model Evaluation on the Test Set\n",
    "\n",
    "\n",
    "### **How It Works:**\n",
    "\n",
    "#### **1. Make Predictions:**\n",
    "```python\n",
    "Y_test_pred = predict(test_images, parameters)\n",
    "```\n",
    "- **`test_images`**: The unseen test set of flattened MNIST images.\n",
    "- **`parameters`**: The trained weights and biases from the model.\n",
    "- **`Y_test_pred`**: The predicted labels for each test sample after performing forward propagation.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Calculate Accuracy:**\n",
    "```python\n",
    "test_accuracy = np.mean(Y_test_pred == test_labels)\n",
    "```\n",
    "- Compares predicted labels (`Y_test_pred`) with actual labels (`test_labels`).\n",
    "- Computes the mean of correct predictions, yielding the **Test Accuracy**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Print the Result:**\n",
    "```python\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "```\n",
    "- The printed result is `Test Accuracy: 0.9717` meaning:\n",
    "  - **97.17% accuracy** on the test set, which is **highly accurate**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why This Is Important:**\n",
    "- **Evaluation on Unseen Data:** The test accuracy measures how well the model generalizes to new data.\n",
    "- **Performance Metric:** High accuracy indicates that the model has learned the data representation effectively.\n",
    "- **Model Validation:** Consistency between training, validation, and test accuracy ensures the model isn't overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5db22b1c-f837-4d9c-8c54-00e12dd26f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fba30d0-ef12-4fb3-8938-832fb6886887",
   "metadata": {},
   "source": [
    "### Analysis of the Model Loss Plot\n",
    "\n",
    "1. **Training Loss (Blue Line):**\n",
    "   - The training loss decreases steadily throughout the epochs, indicating that the model is learning effectively on the training data.\n",
    "   - By the 20th epoch, the training loss approaches near-zero values, suggesting the model has fit the training set well.\n",
    "\n",
    "2. **Validation Loss (Orange Line):**\n",
    "   - The validation loss decreases but at a slower rate compared to the training loss.\n",
    "   - This gap between training and validation loss may suggest some **overfitting** as training loss continues to drop significantly, while validation loss levels off.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Observations:\n",
    "1. **Loss Gap:**\n",
    "   - A small but noticeable gap exists between the training and validation loss.\n",
    "   - This is common in deep learning when the model starts overfitting to the training data.\n",
    "\n",
    "2. **Stability:**\n",
    "   - Both curves are smooth, indicating no irregularities like unstable gradients or poor learning rates.\n",
    "\n",
    "3. **Validation Loss Plateau:**\n",
    "   - The validation loss flattens as the number of epochs increases.\n",
    "   - This indicates that additional training may not further improve the validation performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Recommendations to Address Overfitting:\n",
    "1. **Regularization Techniques:**\n",
    "   - Apply **L2 regularization** (weight decay) to the loss function.\n",
    "   - Add **dropout** layers to the network to reduce overfitting.\n",
    "\n",
    "2. **Early Stopping:**\n",
    "   - Stop training when the validation loss stops improving to prevent overfitting.\n",
    "\n",
    "3. **Data Augmentation:**\n",
    "   - If applicable, augment training data to improve generalization.\n",
    "\n",
    "4. **Reduce Model Complexity:**\n",
    "   - Decrease the number of neurons in hidden layers if the network is overly complex.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
